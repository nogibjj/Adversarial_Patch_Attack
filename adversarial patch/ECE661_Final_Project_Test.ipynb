{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65HDcPRlr4N"
      },
      "source": [
        "Example Github repo\n",
        "\n",
        "https://github.com/A-LinCui/Adversarial_Patch_Attack/blob/master/Attack.py\n",
        "\n",
        "\n",
        "https://github.com/jhayes14/adversarial-patch/tree/master/pretrained_models_pytorch \n",
        "\n",
        "https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial10/Adversarial_Attacks.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9821/3133616188.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n"
          ]
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import numpy as np \n",
        "import scipy.linalg\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOBLC1uKS30q"
      },
      "outputs": [],
      "source": [
        "\n",
        "from resnet20 import ResNetCIFAR\n",
        "# from train_util import train, finetune, test\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from FP_layers import *\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3836355639.py, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from tools import resnet20.py\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# import the model from tools folder\n",
        "from tools import resnet20.py\n",
        "# import the train_util from tools folder\n",
        "from tools import train_util.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trcikfVrVoQb",
        "outputId": "b67ef940-0dc7-4ba9-fecd-aae007a644c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = ResNetCIFAR(num_layers=20, Nbits=None)\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(\"pretrained_model_resnet20.pt\",map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a42Vt3XnkLLw"
      },
      "outputs": [],
      "source": [
        "def test(net):\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "\n",
        "    ])\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    num_val_steps = len(testloader)\n",
        "    val_acc = correct / total\n",
        "    print(\"Test Loss=%.4f, Test accuracy=%.4f\" % (test_loss / (num_val_steps), val_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f3471d569d0e4cbfbc222f3d99702315",
            "c3bdb06270f9459fbfee8112eaf9d28f",
            "b008b3629b4246a2bbc006d2706e001f",
            "a3b3c7f6fdb645c888ffb03ff38a3075",
            "4829db0cbb7c4211a137656af0699bfb",
            "21520b133b864ddfa14e6ed40984c53c",
            "a87e5e05899948ef9aaac20e29275834",
            "824036f44c8a4a048506b8c56aeaefe6",
            "41ec87fe1e684c17bf588ddc33a5b075",
            "d6756319956e4e01a45178abc677e00a",
            "d13352ff8b6d4595aef733d118da6b96"
          ]
        },
        "id": "dTTadV3QV-RZ",
        "outputId": "c3f9e8e7-6858-4307-bf7c-6a9e362ca3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3471d569d0e4cbfbc222f3d99702315",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Test Loss=0.3231, Test accuracy=0.9151\n"
          ]
        }
      ],
      "source": [
        "test(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvpQq9Ynawi7"
      },
      "outputs": [],
      "source": [
        "def gen_mask(img, patch, h_pos=None, w_pos=None):\n",
        "    if (h_pos==None): h_pos = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "    if (w_pos==None): w_pos = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "    applied_patch = torch.tensor(np.zeros(img.shape[1:]))\n",
        "    for i in range(img.shape[0]):\n",
        "        # if (h_pos==None): h_pos = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "        # if (w_pos==None): w_pos = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "        # img[i,:,h_pos:h_pos+patch.shape[1],w_pos:w_pos+patch.shape[2]] = patch\n",
        "        applied_patch[:, h_pos:h_pos+patch.shape[1], w_pos:w_pos+patch.shape[2]] = patch\n",
        "        mask = applied_patch.clone()\n",
        "        mask[mask != 0] = 1.0\n",
        "    return applied_patch, mask #img \n",
        "\n",
        "def place_patch(img, patch, h_pos=None, w_pos=None):\n",
        "    for i in range(img.shape[0]):\n",
        "        if (h_pos==None): h_pos = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "        if (w_pos==None): w_pos = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "        img[i,:,h_pos:h_pos+patch.shape[1],w_pos:w_pos+patch.shape[2]] = patch\n",
        "    return img \n",
        "\n",
        "def train_untargeted_patch(net, epochs, patch_size=7, log_every_n=100, batch_size=128, rand_start=False):\n",
        "    transform_train = transforms.Compose([\n",
        "        # transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    patch_min = -torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size)/torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size)\n",
        "    patch_max = (1.0 - torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size))/torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size)\n",
        "\n",
        "    if rand_start:\n",
        "        patch = nn.Parameter(torch.FloatTensor(3, patch_size, patch_size).uniform_(torch.max(patch_min),torch.min(patch_max)), requires_grad=True)\n",
        "    else:\n",
        "        patch = nn.Parameter(torch.zeros(3, patch_size, patch_size, dtype=torch.float64), requires_grad=True)\n",
        "\n",
        "    print(patch.grad)\n",
        "    optimizer = torch.optim.Adam([patch], lr=1e-1)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, threshold=0.005, threshold_mode='abs', factor=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    global_steps = 0\n",
        "    best_acc = 1\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('\\nEpoch: %d\\tLearning Rate:%f' % (epoch, scheduler.optimizer.param_groups[0]['lr']))\n",
        "        train_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            # Normalize patch using stats of CIFAR-10\n",
        "            # patch_normalized = (torch.clamp(patch,min=0.0,max=1.0) - torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size)) / (torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size))\n",
        "            patch_normalized = torch.clamp(patch, min=patch_min, max=patch_max)\n",
        "            # Place patch\n",
        "            applied_patch, mask = gen_mask(inputs, patch_normalized)\n",
        "            adv_inputs = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), inputs.type(torch.FloatTensor))\n",
        "            # adv_inputs = place_patch(inputs, patch_normalized)\n",
        "            adv_inputs, targets = adv_inputs.to(device), targets.to(device)\n",
        "            outputs = net(adv_inputs)\n",
        "            optimizer.zero_grad()\n",
        "            loss = -criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            patch_grad = patch.grad.data.clone().cpu()\n",
        "            patch = scheduler.optimizer.param_groups[0]['lr'] * patch_grad + patch\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss -= loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            success += predicted.eq(targets).sum().item()\n",
        "            global_steps += 1\n",
        "\n",
        "            if global_steps % log_every_n == 0:\n",
        "                end = time.time()\n",
        "                num_examples_per_second = log_every_n * batch_size / (end - start)\n",
        "                print(\"[Step=%d]\\tLoss=%.4f\\tSuccess=%.4f\\t%.1f examples/second\"\n",
        "                      % (global_steps, train_loss / (batch_idx + 1), 1.0-(success / total), num_examples_per_second))\n",
        "                start = time.time()\n",
        "\n",
        "        \n",
        "\n",
        "        test_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "                patch_normalized = torch.clamp(patch, min=patch_min, max=patch_max)\n",
        "                # adv_inputs = place_patch(inputs, patch_normalized)\n",
        "                applied_patch, mask = gen_mask(inputs, patch_normalized)\n",
        "                adv_inputs = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), inputs.type(torch.FloatTensor))\n",
        "                adv_inputs, targets = adv_inputs.to(device), targets.to(device)\n",
        "                outputs = net(adv_inputs)\n",
        "                loss = -criterion(outputs, targets)\n",
        "\n",
        "                test_loss -= loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                success += predicted.eq(targets).sum().item()\n",
        "        num_val_steps = len(testloader)\n",
        "        val_acc = success / total\n",
        "        print(\"Test Loss=%.4f, Test Success=%.4f\" % (test_loss / (num_val_steps), 1.0-val_acc))\n",
        "\n",
        "        scheduler.step(1.0-success/total)\n",
        "\n",
        "        if val_acc < best_acc:\n",
        "            best_acc = val_acc\n",
        "            print(\"Saving...\")\n",
        "            best_patch = (torch.tanh(patch.cpu().clone().detach())+1)/2\n",
        "\n",
        "    return best_patch, best_acc\n",
        "\n",
        "def train_targeted_patch(net, epochs, target, patch_size=7, log_every_n=100, batch_size=128, rand_start=False):\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        # transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])  \n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    if rand_start:\n",
        "        patch = nn.Parameter(torch.FloatTensor(3, patch_size, patch_size).uniform_(-0.5,0.5), requires_grad=True)\n",
        "    else:\n",
        "        patch = nn.Parameter(torch.zeros(3, patch_size, patch_size, dtype=torch.float64), requires_grad=True)\n",
        "\n",
        "    optimizer = torch.optim.SGD([patch], lr=1e-1, momentum=0.9, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold=0.005, threshold_mode='abs', factor=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    global_steps = 0\n",
        "    best_acc = 1\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('\\nTargeted Attack\\nEpoch: %d\\tLearning Rate:%f' % (epoch, scheduler.optimizer.param_groups[0]['lr']))\n",
        "        train_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, _) in enumerate(trainloader):\n",
        "            # Normalize patch using stats of CIFAR-10\n",
        "            patch_normalized = (torch.tanh(patch) + 1 - 2*torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size)) / (2*torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size))\n",
        "            # Place patch\n",
        "            inputs = place_patch(inputs, patch_normalized)\n",
        "            targets = torch.zeros(inputs.shape[0], dtype=torch.long).fill_(target)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            success += predicted.eq(targets).sum().item()\n",
        "            global_steps += 1\n",
        "\n",
        "            if global_steps % log_every_n == 0:\n",
        "                end = time.time()\n",
        "                num_examples_per_second = log_every_n * batch_size / (end - start)\n",
        "                print(\"[Step=%d]\\tLoss=%.4f\\tSuccess=%.4f\\t%.1f examples/second\"\n",
        "                      % (global_steps, train_loss / (batch_idx + 1), (success / total), num_examples_per_second))\n",
        "                start = time.time()\n",
        "\n",
        "        test_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, _) in enumerate(testloader):\n",
        "                inputs = place_patch(inputs, patch_normalized)\n",
        "                targets = torch.zeros(inputs.shape[0], dtype=torch.long).fill_(target)\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                success += predicted.eq(targets).sum().item()\n",
        "        num_val_steps = len(testloader)\n",
        "        val_acc = success / total\n",
        "        print(\"Test Loss=%.4f, Test Success=%.4f\" % (test_loss / (num_val_steps), val_acc))\n",
        "        scheduler.step(success/total)\n",
        "\n",
        "        if val_acc < best_acc:\n",
        "            best_acc = val_acc\n",
        "            print(\"Saving...\")\n",
        "            best_patch = (torch.tanh(patch.cpu().clone().detach())+1)/2\n",
        "\n",
        "    return best_patch, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PktQoVrfZtX"
      },
      "outputs": [],
      "source": [
        "def random_noise_attack(model, device, dat, eps):\n",
        "    # Add uniform random noise in [-eps,+eps]\n",
        "    x_adv = dat.clone().detach() + torch.FloatTensor(dat.shape).uniform_(-eps, eps).to(device)\n",
        "    # Clip the perturbed datapoints to ensure we are in bounds [0,1]\n",
        "    # x_adv = torch.clamp(x_adv.clone().detach(), 0., 1.)\n",
        "    # Return perturbed samples\n",
        "    return x_adv\n",
        "\n",
        "# Compute the gradient of the loss w.r.t. the input data\n",
        "def gradient_wrt_data(model,device,data,lbl):\n",
        "    dat = data.clone().detach()\n",
        "    dat.requires_grad = True\n",
        "    out = model(dat)\n",
        "    loss = F.cross_entropy(out,lbl)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = dat.grad.data\n",
        "    return data_grad.data.detach() #Q: Why .data again? (dat.grad is already a tensor; infinite .data?)\n",
        "\n",
        "\n",
        "def PGD_attack(model, device, dat, lbl, eps, alpha, iters, rand_start):\n",
        "    # TODO: Implement the PGD attack\n",
        "    # - dat and lbl are tensors\n",
        "    # - eps and alpha are floats\n",
        "    # - iters is an integer\n",
        "    # - rand_start is a bool\n",
        "\n",
        "    # x_nat is the natural (clean) data batch, we .clone().detach()\n",
        "    # to copy it and detach it from our computational graph\n",
        "    x_nat = dat.clone().detach()\n",
        "\n",
        "    # If rand_start is True, add uniform noise to the sample within [-eps,+eps],\n",
        "    # else just copy x_nat \n",
        "    if rand_start:\n",
        "        x_nat_gd = random_noise_attack(model, device, x_nat, eps)\n",
        "\n",
        "    else: \n",
        "        x_nat_gd = x_nat.clone()\n",
        "\n",
        "\n",
        "    # Make sure the sample is projected into original distribution bounds [0,1]\n",
        "    # x_nat_gd = torch.clamp(x_nat_gd, min=0, max=1)\n",
        "\n",
        "    # Iterate over iters\n",
        "    for iter_num in range(iters):\n",
        "        # Compute gradient w.r.t. data (we give you this function, but understand it)\n",
        "        grad = gradient_wrt_data(model, device, x_nat_gd, lbl)\n",
        "        # Perturb the image using the gradient\n",
        "        x_nat_gd = x_nat_gd + alpha * torch.sign(grad)\n",
        "        # Clip the perturbed datapoints to ensure we still satisfy L_infinity constraint\n",
        "        x_nat_gd = torch.clamp(x_nat_gd, min=x_nat-eps, max=x_nat+eps)\n",
        "        # Clip the perturbed datapoints to ensure we are in bounds [0,1]\n",
        "        # x_nat_gd = torch.clamp(x_nat_gd, min=0, max=1)\n",
        "\n",
        "    # Return the final perturbed samples\n",
        "    return x_nat_gd\n",
        "\n",
        "def PGD_attack_example(whitebox, EPS, ITS):\n",
        "    correct = 0.\n",
        "    running_total = 0.\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])  \n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    for batch_idx,(data,labels) in enumerate(trainloader):\n",
        "        data = data.to(device) \n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # TODO: Perform adversarial attack here\n",
        "        ALP = 1.85*(EPS/ITS)\n",
        "        adv_data = PGD_attack(net, device, data, labels, EPS, ALP, ITS, True)\n",
        "        # Sanity checking if adversarial example is \"legal\"\n",
        "        assert(torch.max(torch.abs(adv_data-data)) <= (EPS + 1e-5) )\n",
        "        # assert(adv_data.max() == 1.) #Why has to be 1\n",
        "        # assert(adv_data.min() == 0.)\n",
        "        \n",
        "        # Compute accuracy on perturbed data\n",
        "        with torch.no_grad():\n",
        "            # Stat keeping - whitebox\n",
        "            outputs = whitebox(adv_data)\n",
        "            _,preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            running_total += labels.size(0)\n",
        "        \n",
        "            # Plot some samples\n",
        "        if batch_idx == 1:\n",
        "            plt.figure(figsize=(15,5))\n",
        "            for jj in range(12):\n",
        "                plt.subplot(2,6,jj+1);plt.imshow(adv_data[jj,0].cpu().numpy(),cmap='gray');plt.axis(\"off\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        return correct/running_total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE5jkCA6k-rx",
        "outputId": "165e7a6b-23a6-49b1-ad60-07b870773dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.96875"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PGD_attack_example(net,0.00,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S2O3pqympAY",
        "outputId": "af3de9ff-a865-49ef-f219-2cc588b5ff86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "None\n",
            "\n",
            "Epoch: 0\tLearning Rate:0.100000\n",
            "[Step=100]\tLoss=2.6927\tSuccess=0.4009\t119.3 examples/second\n",
            "[Step=200]\tLoss=3.1807\tSuccess=0.4380\t124.8 examples/second\n",
            "[Step=300]\tLoss=3.3586\tSuccess=0.4516\t125.6 examples/second\n",
            "Test Loss=3.9985, Test Success=0.5035\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\tLearning Rate:0.100000\n",
            "[Step=400]\tLoss=4.0410\tSuccess=0.5122\t97.9 examples/second\n",
            "[Step=500]\tLoss=4.1311\tSuccess=0.5123\t121.4 examples/second\n",
            "[Step=600]\tLoss=3.9806\tSuccess=0.5009\t126.4 examples/second\n",
            "[Step=700]\tLoss=3.9279\tSuccess=0.4969\t124.2 examples/second\n",
            "Test Loss=4.4638, Test Success=0.5365\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\tLearning Rate:0.100000\n",
            "[Step=800]\tLoss=3.4147\tSuccess=0.4766\t97.4 examples/second\n",
            "[Step=900]\tLoss=3.8696\tSuccess=0.4930\t126.0 examples/second\n",
            "[Step=1000]\tLoss=3.7213\tSuccess=0.4814\t123.5 examples/second\n",
            "[Step=1100]\tLoss=3.8203\tSuccess=0.4884\t125.3 examples/second\n",
            "Test Loss=4.2831, Test Success=0.5249\n",
            "\n",
            "Epoch: 3\tLearning Rate:0.100000\n",
            "[Step=1200]\tLoss=4.0403\tSuccess=0.5072\t96.7 examples/second\n",
            "[Step=1300]\tLoss=3.8515\tSuccess=0.4987\t123.6 examples/second\n",
            "[Step=1400]\tLoss=3.8474\tSuccess=0.4952\t125.1 examples/second\n",
            "[Step=1500]\tLoss=3.8870\tSuccess=0.4972\t124.3 examples/second\n",
            "Test Loss=4.1132, Test Success=0.5102\n",
            "\n",
            "Epoch: 4\tLearning Rate:0.100000\n",
            "[Step=1600]\tLoss=3.6223\tSuccess=0.4718\t97.0 examples/second\n",
            "[Step=1700]\tLoss=4.0124\tSuccess=0.4974\t125.8 examples/second\n",
            "[Step=1800]\tLoss=3.8374\tSuccess=0.4881\t125.3 examples/second\n",
            "[Step=1900]\tLoss=3.8670\tSuccess=0.4908\t125.3 examples/second\n",
            "Test Loss=3.7791, Test Success=0.4954\n",
            "\n",
            "Epoch: 5\tLearning Rate:0.100000\n",
            "[Step=2000]\tLoss=3.7073\tSuccess=0.4811\t97.0 examples/second\n",
            "[Step=2100]\tLoss=3.4434\tSuccess=0.4651\t125.4 examples/second\n",
            "[Step=2200]\tLoss=3.5029\tSuccess=0.4714\t126.7 examples/second\n",
            "[Step=2300]\tLoss=3.5946\tSuccess=0.4777\t125.2 examples/second\n",
            "Test Loss=3.5893, Test Success=0.4817\n",
            "\n",
            "Epoch: 6\tLearning Rate:0.100000\n",
            "[Step=2400]\tLoss=4.2303\tSuccess=0.5237\t97.2 examples/second\n",
            "[Step=2500]\tLoss=3.7247\tSuccess=0.4840\t126.6 examples/second\n",
            "[Step=2600]\tLoss=3.7481\tSuccess=0.4874\t123.7 examples/second\n",
            "[Step=2700]\tLoss=3.8424\tSuccess=0.4924\t125.2 examples/second\n",
            "Test Loss=3.9867, Test Success=0.5043\n",
            "\n",
            "Epoch: 7\tLearning Rate:0.100000\n",
            "[Step=2800]\tLoss=3.6148\tSuccess=0.4789\t97.1 examples/second\n",
            "[Step=2900]\tLoss=3.6751\tSuccess=0.4827\t124.5 examples/second\n",
            "[Step=3000]\tLoss=3.6656\tSuccess=0.4824\t125.3 examples/second\n",
            "[Step=3100]\tLoss=3.6976\tSuccess=0.4834\t123.1 examples/second\n",
            "Test Loss=3.9706, Test Success=0.5095\n",
            "\n",
            "Epoch: 8\tLearning Rate:0.100000\n",
            "[Step=3200]\tLoss=3.8356\tSuccess=0.4934\t96.9 examples/second\n"
          ]
        }
      ],
      "source": [
        "rand_patch = []\n",
        "rand_acc = []\n",
        "for i in range(5):\n",
        "  patch, acc = train_untargeted_patch(net,20,rand_start=True)\n",
        "  rand_patch.append(patch)\n",
        "  rand_acc.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZEOcY2azlO6"
      },
      "outputs": [],
      "source": [
        "patch, acc = train_untargeted_patch(net,30)\n",
        "plt.imshow(torch.mean(patch,0),cmap='gray')\n",
        "plt.show()\n",
        "print(patch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7fyzC4LAyfr"
      },
      "outputs": [],
      "source": [
        "print(rand_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IacZgjyrurS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e8ba96d35f524bf788e0a066ae8555804e9c3c2c45d7eaf088b255e4838dd8cc"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21520b133b864ddfa14e6ed40984c53c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ec87fe1e684c17bf588ddc33a5b075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4829db0cbb7c4211a137656af0699bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824036f44c8a4a048506b8c56aeaefe6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b3c7f6fdb645c888ffb03ff38a3075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6756319956e4e01a45178abc677e00a",
            "placeholder": "​",
            "style": "IPY_MODEL_d13352ff8b6d4595aef733d118da6b96",
            "value": " 170498071/170498071 [00:02&lt;00:00, 89986789.06it/s]"
          }
        },
        "a87e5e05899948ef9aaac20e29275834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b008b3629b4246a2bbc006d2706e001f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824036f44c8a4a048506b8c56aeaefe6",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ec87fe1e684c17bf588ddc33a5b075",
            "value": 170498071
          }
        },
        "c3bdb06270f9459fbfee8112eaf9d28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21520b133b864ddfa14e6ed40984c53c",
            "placeholder": "​",
            "style": "IPY_MODEL_a87e5e05899948ef9aaac20e29275834",
            "value": "100%"
          }
        },
        "d13352ff8b6d4595aef733d118da6b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6756319956e4e01a45178abc677e00a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3471d569d0e4cbfbc222f3d99702315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3bdb06270f9459fbfee8112eaf9d28f",
              "IPY_MODEL_b008b3629b4246a2bbc006d2706e001f",
              "IPY_MODEL_a3b3c7f6fdb645c888ffb03ff38a3075"
            ],
            "layout": "IPY_MODEL_4829db0cbb7c4211a137656af0699bfb"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
