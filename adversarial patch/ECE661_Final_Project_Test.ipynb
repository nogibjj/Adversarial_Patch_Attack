{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l65HDcPRlr4N"
      },
      "source": [
        "Example Github repo\n",
        "\n",
        "https://github.com/A-LinCui/Adversarial_Patch_Attack/blob/master/Attack.py\n",
        "\n",
        "\n",
        "https://github.com/jhayes14/adversarial-patch/tree/master/pretrained_models_pytorch \n",
        "\n",
        "https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial10/Adversarial_Attacks.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9821/1134565456.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n"
          ]
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import numpy as np \n",
        "import scipy.linalg\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "\n",
        "# from tools\n",
        "%cd ..\n",
        "from tools.resnet20 import ResNetCIFAR\n",
        "from tools.train_util import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fOBLC1uKS30q"
      },
      "outputs": [],
      "source": [
        "# set the device to GPU if available, else CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trcikfVrVoQb",
        "outputId": "b67ef940-0dc7-4ba9-fecd-aae007a644c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = ResNetCIFAR(num_layers=20, Nbits=None)\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(\"/workspaces/Adversarial_Patch_Attack/tools/pretrained_model_resnet20.pt\",map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "a42Vt3XnkLLw"
      },
      "outputs": [],
      "source": [
        "def test(net):\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "\n",
        "    ])\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root=\"/workspaces/Adversarial_Patch_Attack/data\", train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    num_val_steps = len(testloader)\n",
        "    val_acc = correct / total\n",
        "    print(\"Test Loss=%.4f, Test accuracy=%.4f\" % (test_loss / (num_val_steps), val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f3471d569d0e4cbfbc222f3d99702315",
            "c3bdb06270f9459fbfee8112eaf9d28f",
            "b008b3629b4246a2bbc006d2706e001f",
            "a3b3c7f6fdb645c888ffb03ff38a3075",
            "4829db0cbb7c4211a137656af0699bfb",
            "21520b133b864ddfa14e6ed40984c53c",
            "a87e5e05899948ef9aaac20e29275834",
            "824036f44c8a4a048506b8c56aeaefe6",
            "41ec87fe1e684c17bf588ddc33a5b075",
            "d6756319956e4e01a45178abc677e00a",
            "d13352ff8b6d4595aef733d118da6b96"
          ]
        },
        "id": "dTTadV3QV-RZ",
        "outputId": "c3f9e8e7-6858-4307-bf7c-6a9e362ca3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Test Loss=0.3231, Test accuracy=0.9151\n"
          ]
        }
      ],
      "source": [
        "test(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_dir = \"/workspaces/Adversarial_Patch_Attack/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "NvpQq9Ynawi7"
      },
      "outputs": [],
      "source": [
        "def gen_mask(img, patch, h_pos=None, w_pos=None):\n",
        "    if (h_pos==None): h_pos = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "    if (w_pos==None): w_pos = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "    applied_patch = torch.tensor(np.zeros(img.shape[1:]))\n",
        "    for i in range(img.shape[0]):\n",
        "        # if (h_pos==None): h_pos = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "        # if (w_pos==None): w_pos = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "        # img[i,:,h_pos:h_pos+patch.shape[1],w_pos:w_pos+patch.shape[2]] = patch\n",
        "        applied_patch[:, h_pos:h_pos+patch.shape[1], w_pos:w_pos+patch.shape[2]] = patch\n",
        "        mask = applied_patch.clone()\n",
        "        mask[mask != 0] = 1.0\n",
        "    return applied_patch, mask #img \n",
        "\n",
        "def place_patch(img, patch, h_pos=None, w_pos=None):\n",
        "    for i in range(img.shape[0]):\n",
        "        if (h_pos==None): h_pos = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "        if (w_pos==None): w_pos = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "        img[i,:,h_pos:h_pos+patch.shape[1],w_pos:w_pos+patch.shape[2]] = patch\n",
        "    return img \n",
        "\n",
        "def train_untargeted_patch(net, epochs, patch_size=7, log_every_n=100, batch_size=128, rand_start=False):\n",
        "    transform_train = transforms.Compose([\n",
        "        # transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=root_dir, train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "    testset = torchvision.datasets.CIFAR10(root=root_dir, train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    patch_min = -torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size)/torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size)\n",
        "    patch_max = (1.0 - torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size))/torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size)\n",
        "\n",
        "    if rand_start:\n",
        "        patch = nn.Parameter(torch.FloatTensor(3, patch_size, patch_size).uniform_(torch.max(patch_min),torch.min(patch_max)), requires_grad=True)\n",
        "    else:\n",
        "        patch = nn.Parameter(torch.zeros(3, patch_size, patch_size, dtype=torch.float64), requires_grad=True)\n",
        "\n",
        "    print(patch.grad)\n",
        "    optimizer = torch.optim.Adam([patch], lr=1e-1)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, threshold=0.005, threshold_mode='abs', factor=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    global_steps = 0\n",
        "    best_acc = 1\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('\\nEpoch: %d\\tLearning Rate:%f' % (epoch, scheduler.optimizer.param_groups[0]['lr']))\n",
        "        train_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            # Normalize patch using stats of CIFAR-10\n",
        "            # patch_normalized = (torch.clamp(patch,min=0.0,max=1.0) - torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size)) / (torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size))\n",
        "            patch_normalized = torch.clamp(patch, min=patch_min, max=patch_max)\n",
        "            # Place patch\n",
        "            applied_patch, mask = gen_mask(inputs, patch_normalized)\n",
        "            adv_inputs = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), inputs.type(torch.FloatTensor))\n",
        "            # adv_inputs = place_patch(inputs, patch_normalized)\n",
        "            adv_inputs, targets = adv_inputs.to(device), targets.to(device)\n",
        "            outputs = net(adv_inputs)\n",
        "            optimizer.zero_grad()\n",
        "            loss = -criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            #patch_grad = patch.grad.data.clone().cpu()\n",
        "            #patch = scheduler.optimizer.param_groups[0]['lr'] * patch_grad + patch\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss -= loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            success += predicted.eq(targets).sum().item()\n",
        "            global_steps += 1\n",
        "\n",
        "            if global_steps % log_every_n == 0:\n",
        "                end = time.time()\n",
        "                num_examples_per_second = log_every_n * batch_size / (end - start)\n",
        "                print(\"[Step=%d]\\tLoss=%.4f\\tSuccess=%.4f\\t%.1f examples/second\"\n",
        "                      % (global_steps, train_loss / (batch_idx + 1), 1.0-(success / total), num_examples_per_second))\n",
        "                start = time.time()\n",
        "\n",
        "        \n",
        "\n",
        "        test_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "                patch_normalized = torch.clamp(patch, min=patch_min, max=patch_max)\n",
        "                # adv_inputs = place_patch(inputs, patch_normalized)\n",
        "                applied_patch, mask = gen_mask(inputs, patch_normalized)\n",
        "                adv_inputs = torch.mul(mask.type(torch.FloatTensor), applied_patch.type(torch.FloatTensor)) + torch.mul((1 - mask.type(torch.FloatTensor)), inputs.type(torch.FloatTensor))\n",
        "                adv_inputs, targets = adv_inputs.to(device), targets.to(device)\n",
        "                outputs = net(adv_inputs)\n",
        "                loss = -criterion(outputs, targets)\n",
        "\n",
        "                test_loss -= loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                success += predicted.eq(targets).sum().item()\n",
        "        num_val_steps = len(testloader)\n",
        "        val_acc = success / total\n",
        "        print(\"Test Loss=%.4f, Test Success=%.4f\" % (test_loss / (num_val_steps), 1.0-val_acc))\n",
        "\n",
        "        scheduler.step(1.0-success/total)\n",
        "\n",
        "        if val_acc < best_acc:\n",
        "            best_acc = val_acc\n",
        "            print(\"Saving...\")\n",
        "            best_patch = (torch.tanh(patch.cpu().clone().detach())+1)/2\n",
        "\n",
        "    return best_patch, best_acc\n",
        "\n",
        "def train_targeted_patch(net, epochs, target, patch_size=7, log_every_n=100, batch_size=128, rand_start=False):\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        # transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])  \n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=root_dir, train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "    testset = torchvision.datasets.CIFAR10(root=root_dir, train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    if rand_start:\n",
        "        patch = nn.Parameter(torch.FloatTensor(3, patch_size, patch_size).uniform_(-0.5,0.5), requires_grad=True)\n",
        "    else:\n",
        "        patch = nn.Parameter(torch.zeros(3, patch_size, patch_size, dtype=torch.float64), requires_grad=True)\n",
        "\n",
        "    optimizer = torch.optim.SGD([patch], lr=1e-1, momentum=0.9, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold=0.005, threshold_mode='abs', factor=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    global_steps = 0\n",
        "    best_acc = 1\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('\\nTargeted Attack\\nEpoch: %d\\tLearning Rate:%f' % (epoch, scheduler.optimizer.param_groups[0]['lr']))\n",
        "        train_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, _) in enumerate(trainloader):\n",
        "            # Normalize patch using stats of CIFAR-10\n",
        "            patch_normalized = (torch.tanh(patch) + 1 - 2*torch.tensor([0.4914,0.4822,0.4465])[:,None,None].expand(-1,patch_size,patch_size)) / (2*torch.tensor([0.2023,0.1994,0.2010])[:,None,None].expand(-1,patch_size,patch_size))\n",
        "            # Place patch\n",
        "            inputs = place_patch(inputs, patch_normalized)\n",
        "            targets = torch.zeros(inputs.shape[0], dtype=torch.long).fill_(target)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            success += predicted.eq(targets).sum().item()\n",
        "            global_steps += 1\n",
        "\n",
        "            if global_steps % log_every_n == 0:\n",
        "                end = time.time()\n",
        "                num_examples_per_second = log_every_n * batch_size / (end - start)\n",
        "                print(\"[Step=%d]\\tLoss=%.4f\\tSuccess=%.4f\\t%.1f examples/second\"\n",
        "                      % (global_steps, train_loss / (batch_idx + 1), (success / total), num_examples_per_second))\n",
        "                start = time.time()\n",
        "\n",
        "        test_loss = 0\n",
        "        success = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, _) in enumerate(testloader):\n",
        "                inputs = place_patch(inputs, patch_normalized)\n",
        "                targets = torch.zeros(inputs.shape[0], dtype=torch.long).fill_(target)\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                success += predicted.eq(targets).sum().item()\n",
        "        num_val_steps = len(testloader)\n",
        "        val_acc = success / total\n",
        "        print(\"Test Loss=%.4f, Test Success=%.4f\" % (test_loss / (num_val_steps), val_acc))\n",
        "        scheduler.step(success/total)\n",
        "\n",
        "        if val_acc < best_acc:\n",
        "            best_acc = val_acc\n",
        "            print(\"Saving...\")\n",
        "            best_patch = (torch.tanh(patch.cpu().clone().detach())+1)/2\n",
        "\n",
        "    return best_patch, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "-PktQoVrfZtX"
      },
      "outputs": [],
      "source": [
        "def random_noise_attack(model, device, dat, eps):\n",
        "    # Add uniform random noise in [-eps,+eps]\n",
        "    x_adv = dat.clone().detach() + torch.FloatTensor(dat.shape).uniform_(-eps, eps).to(device)\n",
        "    # Clip the perturbed datapoints to ensure we are in bounds [0,1]\n",
        "    # x_adv = torch.clamp(x_adv.clone().detach(), 0., 1.)\n",
        "    # Return perturbed samples\n",
        "    return x_adv\n",
        "\n",
        "# Compute the gradient of the loss w.r.t. the input data\n",
        "def gradient_wrt_data(model,device,data,lbl):\n",
        "    dat = data.clone().detach()\n",
        "    dat.requires_grad = True\n",
        "    out = model(dat)\n",
        "    loss = F.cross_entropy(out,lbl)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = dat.grad.data\n",
        "    return data_grad.data.detach() #Q: Why .data again? (dat.grad is already a tensor; infinite .data?)\n",
        "\n",
        "def PGD_attack(model, device, dat, lbl, eps, alpha, iters, rand_start):\n",
        "    # TODO: Implement the PGD attack\n",
        "    # - dat and lbl are tensors\n",
        "    # - eps and alpha are floats\n",
        "    # - iters is an integer\n",
        "    # - rand_start is a bool\n",
        "\n",
        "    # x_nat is the natural (clean) data batch, we .clone().detach()\n",
        "    # to copy it and detach it from our computational graph\n",
        "    x_nat = dat.clone().detach()\n",
        "\n",
        "    # If rand_start is True, add uniform noise to the sample within [-eps,+eps],\n",
        "    # else just copy x_nat \n",
        "    if rand_start:\n",
        "        x_nat_gd = random_noise_attack(model, device, x_nat, eps)\n",
        "\n",
        "    else: \n",
        "        x_nat_gd = x_nat.clone()\n",
        "\n",
        "\n",
        "    # Make sure the sample is projected into original distribution bounds [0,1]\n",
        "    # x_nat_gd = torch.clamp(x_nat_gd, min=0, max=1)\n",
        "\n",
        "    # Iterate over iters\n",
        "    for iter_num in range(iters):\n",
        "        # Compute gradient w.r.t. data (we give you this function, but understand it)\n",
        "        grad = gradient_wrt_data(model, device, x_nat_gd, lbl)\n",
        "        # Perturb the image using the gradient\n",
        "        x_nat_gd = x_nat_gd + alpha * torch.sign(grad)\n",
        "        # Clip the perturbed datapoints to ensure we still satisfy L_infinity constraint\n",
        "        x_nat_gd = torch.clamp(x_nat_gd, min=x_nat-eps, max=x_nat+eps)\n",
        "        # Clip the perturbed datapoints to ensure we are in bounds [0,1]\n",
        "        # x_nat_gd = torch.clamp(x_nat_gd, min=0, max=1)\n",
        "\n",
        "    # Return the final perturbed samples\n",
        "    return x_nat_gd\n",
        "\n",
        "def PGD_attack_example(whitebox, EPS, ITS):\n",
        "    correct = 0.\n",
        "    running_total = 0.\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])  \n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=root_dir, train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "    testset = torchvision.datasets.CIFAR10(root=root_dir, train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    for batch_idx,(data,labels) in enumerate(trainloader):\n",
        "        data = data.to(device) \n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # TODO: Perform adversarial attack here\n",
        "        ALP = 1.85*(EPS/ITS)\n",
        "        adv_data = PGD_attack(net, device, data, labels, EPS, ALP, ITS, True)\n",
        "        # Sanity checking if adversarial example is \"legal\"\n",
        "        assert(torch.max(torch.abs(adv_data-data)) <= (EPS + 1e-5) )\n",
        "        # assert(adv_data.max() == 1.) #Why has to be 1\n",
        "        # assert(adv_data.min() == 0.)\n",
        "        \n",
        "        # Compute accuracy on perturbed data\n",
        "        with torch.no_grad():\n",
        "            # Stat keeping - whitebox\n",
        "            outputs = whitebox(adv_data)\n",
        "            _,preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            running_total += labels.size(0)\n",
        "        \n",
        "            # Plot some samples\n",
        "        if batch_idx == 1:\n",
        "            plt.figure(figsize=(15,5))\n",
        "            for jj in range(12):\n",
        "                plt.subplot(2,6,jj+1);plt.imshow(adv_data[jj,0].cpu().numpy(),cmap='gray');plt.axis(\"off\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        return correct/running_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE5jkCA6k-rx",
        "outputId": "165e7a6b-23a6-49b1-ad60-07b870773dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.984375"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PGD_attack_example(net,0.00,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# generate patch with input sizes and class label\n",
        "def generate_patch(class_labels, patch_sizes):\n",
        "    # return a dictionary of patches\n",
        "    patches = {}\n",
        "    for class_label in class_labels:\n",
        "        patches[class_label] = dict()\n",
        "        for patch_size in patch_sizes:\n",
        "            # if pretrained patch is available, load it\n",
        "            if os.path.exists('patch_{}_{}.pt'.format(class_label, patch_size)):\n",
        "                patches[class_label][patch_size] = torch.load('patch_{}_{}.pt'.format(class_label, patch_size))\n",
        "            # otherwise, train a new patch\n",
        "            else:\n",
        "                patches[class_label][patch_size] = train_patch(class_label, patch_size)\n",
        "                torch.save(patches[class_label][patch_size], 'patch_{}_{}.pt'.format(class_label, patch_size))\n",
        "            # \n",
        "    return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_patches(class_names, patch_sizes):\n",
        "    result_dict = dict()\n",
        "\n",
        "    # Loop over all classes and patch sizes\n",
        "    for name in class_names:\n",
        "        result_dict[name] = dict()\n",
        "        for patch_size in patch_sizes:\n",
        "            # Get target class index\n",
        "            c = label_names.index(name)\n",
        "            file_name = os.path.join(CHECKPOINT_PATH, f\"{name}_{patch_size}_patch.pt\")\n",
        "            # Load patch if pretrained file exists, otherwise start training\n",
        "            if not os.path.isfile(file_name):\n",
        "                patch, val_results = patch_attack(pretrained_model, target_class=c, patch_size=patch_size, num_epochs=5)\n",
        "                print(f\"Validation results for {name} and {patch_size}:\", val_results)\n",
        "                torch.save(patch, file_name)\n",
        "            else:\n",
        "                patch = torch.load(file_name)\n",
        "            # Load evaluation results if exist, otherwise manually evaluate the patch\n",
        "            if name in json_results:\n",
        "                results = json_results[name][str(patch_size)]\n",
        "            else:\n",
        "                results = eval_patch(pretrained_model, patch, data_loader, target_class=c)    \n",
        "            \n",
        "            # Store results and the patches in a dict for better access\n",
        "            result_dict[name][patch_size] = {\n",
        "                \"results\": results,\n",
        "                \"patch\": patch\n",
        "            }\n",
        "        \n",
        "    return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "patch_sizes = [3,5,7,16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "aZEOcY2azlO6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "None\n",
            "\n",
            "Epoch: 0\tLearning Rate:0.100000\n",
            "[Step=100]\tLoss=1.7410\tSuccess=0.3115\t503.1 examples/second\n",
            "[Step=200]\tLoss=2.3562\tSuccess=0.3814\t531.2 examples/second\n",
            "[Step=300]\tLoss=2.7906\tSuccess=0.4200\t535.0 examples/second\n",
            "Test Loss=3.8536, Test Success=0.5084\n",
            "Saving...\n",
            "\n",
            "Epoch: 1\tLearning Rate:0.100000\n",
            "[Step=400]\tLoss=3.0686\tSuccess=0.4540\t394.9 examples/second\n",
            "[Step=500]\tLoss=3.2885\tSuccess=0.4751\t508.2 examples/second\n",
            "[Step=600]\tLoss=3.3154\tSuccess=0.4715\t451.4 examples/second\n",
            "[Step=700]\tLoss=3.3019\tSuccess=0.4699\t449.9 examples/second\n",
            "Test Loss=3.5786, Test Success=0.4976\n",
            "\n",
            "Epoch: 2\tLearning Rate:0.100000\n",
            "[Step=800]\tLoss=2.9888\tSuccess=0.4431\t347.8 examples/second\n",
            "[Step=900]\tLoss=3.2397\tSuccess=0.4680\t468.1 examples/second\n",
            "[Step=1000]\tLoss=3.2933\tSuccess=0.4710\t477.1 examples/second\n",
            "[Step=1100]\tLoss=3.3654\tSuccess=0.4759\t470.1 examples/second\n",
            "Test Loss=3.5435, Test Success=0.4865\n",
            "\n",
            "Epoch: 3\tLearning Rate:0.100000\n",
            "[Step=1200]\tLoss=3.8118\tSuccess=0.5020\t368.0 examples/second\n",
            "[Step=1300]\tLoss=3.5280\tSuccess=0.4895\t524.4 examples/second\n",
            "[Step=1400]\tLoss=3.4487\tSuccess=0.4837\t525.6 examples/second\n",
            "[Step=1500]\tLoss=3.4035\tSuccess=0.4794\t528.8 examples/second\n",
            "Test Loss=4.0443, Test Success=0.5231\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\tLearning Rate:0.100000\n",
            "[Step=1600]\tLoss=3.6610\tSuccess=0.5017\t391.3 examples/second\n",
            "[Step=1700]\tLoss=3.4241\tSuccess=0.4843\t523.4 examples/second\n",
            "[Step=1800]\tLoss=3.4133\tSuccess=0.4839\t526.7 examples/second\n",
            "[Step=1900]\tLoss=3.3205\tSuccess=0.4754\t513.6 examples/second\n",
            "Test Loss=3.7858, Test Success=0.5008\n",
            "\n",
            "Epoch: 5\tLearning Rate:0.100000\n",
            "[Step=2000]\tLoss=3.0689\tSuccess=0.4606\t393.4 examples/second\n",
            "[Step=2100]\tLoss=3.2424\tSuccess=0.4679\t522.1 examples/second\n",
            "[Step=2200]\tLoss=3.3905\tSuccess=0.4794\t515.7 examples/second\n",
            "[Step=2300]\tLoss=3.3807\tSuccess=0.4796\t505.0 examples/second\n",
            "Test Loss=3.8256, Test Success=0.5130\n",
            "\n",
            "Epoch: 6\tLearning Rate:0.100000\n",
            "[Step=2400]\tLoss=3.5783\tSuccess=0.4931\t381.0 examples/second\n",
            "[Step=2500]\tLoss=3.3297\tSuccess=0.4714\t524.3 examples/second\n",
            "[Step=2600]\tLoss=3.4272\tSuccess=0.4799\t526.0 examples/second\n",
            "[Step=2700]\tLoss=3.4706\tSuccess=0.4834\t528.5 examples/second\n",
            "Test Loss=3.6788, Test Success=0.5055\n",
            "\n",
            "Epoch: 7\tLearning Rate:0.100000\n",
            "[Step=2800]\tLoss=3.3993\tSuccess=0.4793\t389.5 examples/second\n",
            "[Step=2900]\tLoss=3.3184\tSuccess=0.4709\t520.3 examples/second\n",
            "[Step=3000]\tLoss=3.3712\tSuccess=0.4764\t514.4 examples/second\n",
            "[Step=3100]\tLoss=3.3510\tSuccess=0.4742\t510.4 examples/second\n",
            "Test Loss=3.9450, Test Success=0.5168\n",
            "\n",
            "Epoch: 8\tLearning Rate:0.100000\n",
            "[Step=3200]\tLoss=3.4315\tSuccess=0.4838\t394.2 examples/second\n",
            "[Step=3300]\tLoss=3.6406\tSuccess=0.5006\t531.9 examples/second\n",
            "[Step=3400]\tLoss=3.6053\tSuccess=0.4996\t527.7 examples/second\n",
            "[Step=3500]\tLoss=3.5507\tSuccess=0.4944\t517.4 examples/second\n",
            "Test Loss=3.5991, Test Success=0.4966\n",
            "\n",
            "Epoch: 9\tLearning Rate:0.010000\n",
            "[Step=3600]\tLoss=3.2651\tSuccess=0.4639\t390.6 examples/second\n",
            "[Step=3700]\tLoss=3.2896\tSuccess=0.4687\t523.9 examples/second\n",
            "[Step=3800]\tLoss=3.3345\tSuccess=0.4728\t518.7 examples/second\n",
            "[Step=3900]\tLoss=3.4012\tSuccess=0.4778\t515.0 examples/second\n",
            "Test Loss=3.9094, Test Success=0.5228\n",
            "\n",
            "Epoch: 10\tLearning Rate:0.010000\n",
            "[Step=4000]\tLoss=3.5604\tSuccess=0.4902\t390.3 examples/second\n",
            "[Step=4100]\tLoss=3.5398\tSuccess=0.4915\t520.4 examples/second\n",
            "[Step=4200]\tLoss=3.4809\tSuccess=0.4862\t521.6 examples/second\n",
            "[Step=4300]\tLoss=3.4996\tSuccess=0.4877\t531.0 examples/second\n",
            "Test Loss=3.5963, Test Success=0.4921\n",
            "\n",
            "Epoch: 11\tLearning Rate:0.010000\n",
            "[Step=4400]\tLoss=3.3614\tSuccess=0.4762\t381.1 examples/second\n",
            "[Step=4500]\tLoss=3.3612\tSuccess=0.4745\t523.0 examples/second\n",
            "[Step=4600]\tLoss=3.3951\tSuccess=0.4774\t528.4 examples/second\n",
            "Test Loss=3.7610, Test Success=0.5019\n",
            "\n",
            "Epoch: 12\tLearning Rate:0.010000\n",
            "[Step=4700]\tLoss=3.3976\tSuccess=0.4697\t387.7 examples/second\n",
            "[Step=4800]\tLoss=3.6445\tSuccess=0.4983\t527.3 examples/second\n",
            "[Step=4900]\tLoss=3.5297\tSuccess=0.4908\t528.5 examples/second\n",
            "[Step=5000]\tLoss=3.4454\tSuccess=0.4855\t523.4 examples/second\n",
            "Test Loss=3.4555, Test Success=0.4845\n",
            "\n",
            "Epoch: 13\tLearning Rate:0.010000\n",
            "[Step=5100]\tLoss=3.6640\tSuccess=0.4991\t399.4 examples/second\n",
            "[Step=5200]\tLoss=3.1170\tSuccess=0.4568\t511.3 examples/second\n",
            "[Step=5300]\tLoss=3.2221\tSuccess=0.4655\t519.5 examples/second\n",
            "[Step=5400]\tLoss=3.3247\tSuccess=0.4738\t527.9 examples/second\n",
            "Test Loss=3.4598, Test Success=0.4858\n",
            "\n",
            "Epoch: 14\tLearning Rate:0.010000\n",
            "[Step=5500]\tLoss=3.9274\tSuccess=0.5093\t389.7 examples/second\n",
            "[Step=5600]\tLoss=3.7346\tSuccess=0.5012\t515.1 examples/second\n",
            "[Step=5700]\tLoss=3.5670\tSuccess=0.4896\t521.9 examples/second\n",
            "[Step=5800]\tLoss=3.4799\tSuccess=0.4814\t522.8 examples/second\n",
            "Test Loss=3.9051, Test Success=0.5199\n",
            "\n",
            "Epoch: 15\tLearning Rate:0.001000\n",
            "[Step=5900]\tLoss=3.4896\tSuccess=0.4882\t389.2 examples/second\n",
            "[Step=6000]\tLoss=3.5294\tSuccess=0.4871\t526.7 examples/second\n",
            "[Step=6100]\tLoss=3.4315\tSuccess=0.4802\t532.9 examples/second\n",
            "[Step=6200]\tLoss=3.3469\tSuccess=0.4744\t537.2 examples/second\n",
            "Test Loss=3.9218, Test Success=0.5182\n",
            "\n",
            "Epoch: 16\tLearning Rate:0.001000\n",
            "[Step=6300]\tLoss=3.2248\tSuccess=0.4716\t397.5 examples/second\n",
            "[Step=6400]\tLoss=3.3718\tSuccess=0.4792\t523.3 examples/second\n",
            "[Step=6500]\tLoss=3.3953\tSuccess=0.4816\t524.6 examples/second\n",
            "[Step=6600]\tLoss=3.4349\tSuccess=0.4841\t528.0 examples/second\n",
            "Test Loss=3.8160, Test Success=0.5075\n",
            "\n",
            "Epoch: 17\tLearning Rate:0.001000\n",
            "[Step=6700]\tLoss=3.2881\tSuccess=0.4637\t393.8 examples/second\n",
            "[Step=6800]\tLoss=3.3494\tSuccess=0.4747\t527.8 examples/second\n",
            "[Step=6900]\tLoss=3.4448\tSuccess=0.4839\t522.8 examples/second\n",
            "[Step=7000]\tLoss=3.4296\tSuccess=0.4811\t528.3 examples/second\n",
            "Test Loss=3.7602, Test Success=0.5085\n",
            "\n",
            "Epoch: 18\tLearning Rate:0.001000\n",
            "[Step=7100]\tLoss=3.0274\tSuccess=0.4540\t396.5 examples/second\n",
            "[Step=7200]\tLoss=3.2282\tSuccess=0.4684\t537.4 examples/second\n",
            "[Step=7300]\tLoss=3.3097\tSuccess=0.4736\t532.9 examples/second\n",
            "[Step=7400]\tLoss=3.3477\tSuccess=0.4775\t536.0 examples/second\n",
            "Test Loss=3.8223, Test Success=0.5099\n",
            "\n",
            "Epoch: 19\tLearning Rate:0.001000\n",
            "[Step=7500]\tLoss=3.2512\tSuccess=0.4636\t360.2 examples/second\n",
            "[Step=7600]\tLoss=3.3287\tSuccess=0.4734\t527.3 examples/second\n",
            "[Step=7700]\tLoss=3.3642\tSuccess=0.4749\t533.1 examples/second\n",
            "[Step=7800]\tLoss=3.3286\tSuccess=0.4704\t554.4 examples/second\n",
            "Test Loss=3.5285, Test Success=0.4877\n",
            "\n",
            "Epoch: 20\tLearning Rate:0.001000\n",
            "[Step=7900]\tLoss=3.3132\tSuccess=0.4795\t404.3 examples/second\n",
            "[Step=8000]\tLoss=3.3362\tSuccess=0.4745\t534.1 examples/second\n",
            "[Step=8100]\tLoss=3.2948\tSuccess=0.4733\t540.6 examples/second\n",
            "[Step=8200]\tLoss=3.2799\tSuccess=0.4733\t542.9 examples/second\n",
            "Test Loss=3.7507, Test Success=0.5033\n",
            "\n",
            "Epoch: 21\tLearning Rate:0.000100\n",
            "[Step=8300]\tLoss=3.5953\tSuccess=0.4898\t405.1 examples/second\n",
            "[Step=8400]\tLoss=3.4650\tSuccess=0.4835\t529.6 examples/second\n",
            "[Step=8500]\tLoss=3.4884\tSuccess=0.4838\t543.4 examples/second\n",
            "[Step=8600]\tLoss=3.3991\tSuccess=0.4782\t536.1 examples/second\n",
            "Test Loss=3.8090, Test Success=0.5066\n",
            "\n",
            "Epoch: 22\tLearning Rate:0.000100\n",
            "[Step=8700]\tLoss=3.1286\tSuccess=0.4597\t399.5 examples/second\n",
            "[Step=8800]\tLoss=3.2889\tSuccess=0.4747\t538.5 examples/second\n",
            "[Step=8900]\tLoss=3.3173\tSuccess=0.4775\t532.8 examples/second\n",
            "Test Loss=3.4249, Test Success=0.4886\n",
            "\n",
            "Epoch: 23\tLearning Rate:0.000100\n",
            "[Step=9000]\tLoss=3.1064\tSuccess=0.4554\t405.8 examples/second\n",
            "[Step=9100]\tLoss=3.5936\tSuccess=0.4955\t538.8 examples/second\n",
            "[Step=9200]\tLoss=3.4884\tSuccess=0.4861\t554.9 examples/second\n",
            "[Step=9300]\tLoss=3.4955\tSuccess=0.4878\t548.5 examples/second\n",
            "Test Loss=3.9967, Test Success=0.5199\n",
            "\n",
            "Epoch: 24\tLearning Rate:0.000100\n",
            "[Step=9400]\tLoss=3.5346\tSuccess=0.4810\t413.7 examples/second\n",
            "[Step=9500]\tLoss=3.2775\tSuccess=0.4630\t549.0 examples/second\n",
            "[Step=9600]\tLoss=3.2424\tSuccess=0.4637\t545.5 examples/second\n",
            "[Step=9700]\tLoss=3.3299\tSuccess=0.4739\t549.1 examples/second\n",
            "Test Loss=3.7149, Test Success=0.5028\n",
            "\n",
            "Epoch: 25\tLearning Rate:0.000100\n",
            "[Step=9800]\tLoss=3.0674\tSuccess=0.4569\t393.4 examples/second\n",
            "[Step=9900]\tLoss=3.4454\tSuccess=0.4852\t528.8 examples/second\n",
            "[Step=10000]\tLoss=3.5527\tSuccess=0.4931\t532.5 examples/second\n",
            "[Step=10100]\tLoss=3.5870\tSuccess=0.4951\t544.0 examples/second\n",
            "Test Loss=3.6961, Test Success=0.5038\n",
            "\n",
            "Epoch: 26\tLearning Rate:0.000100\n",
            "[Step=10200]\tLoss=3.2039\tSuccess=0.4529\t398.8 examples/second\n",
            "[Step=10300]\tLoss=3.0106\tSuccess=0.4408\t531.3 examples/second\n",
            "[Step=10400]\tLoss=3.1931\tSuccess=0.4582\t527.9 examples/second\n",
            "[Step=10500]\tLoss=3.3237\tSuccess=0.4688\t526.9 examples/second\n",
            "Test Loss=3.9769, Test Success=0.5198\n",
            "\n",
            "Epoch: 27\tLearning Rate:0.000010\n",
            "[Step=10600]\tLoss=3.2411\tSuccess=0.4655\t398.1 examples/second\n",
            "[Step=10700]\tLoss=3.2081\tSuccess=0.4652\t531.2 examples/second\n",
            "[Step=10800]\tLoss=3.3370\tSuccess=0.4747\t527.3 examples/second\n",
            "[Step=10900]\tLoss=3.3796\tSuccess=0.4786\t534.7 examples/second\n"
          ]
        }
      ],
      "source": [
        "patch, acc = train_untargeted_patch(net,30)\n",
        "plt.imshow(torch.mean(patch,0),cmap='gray')\n",
        "plt.show()\n",
        "print(patch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7IacZgjyrurS"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_targeted_patch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train targeted patch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m patch, acc \u001b[39m=\u001b[39m train_targeted_patch(net,\u001b[39m30\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mimshow(torch\u001b[39m.\u001b[39mmean(patch,\u001b[39m0\u001b[39m),cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_targeted_patch' is not defined"
          ]
        }
      ],
      "source": [
        "# train targeted patch\n",
        "patch, acc = train_targeted_patch(net,30)\n",
        "plt.imshow(torch.mean(patch,0),cmap='gray')\n",
        "plt.show()\n",
        "print(patch)\n",
        "print(acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e8ba96d35f524bf788e0a066ae8555804e9c3c2c45d7eaf088b255e4838dd8cc"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21520b133b864ddfa14e6ed40984c53c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ec87fe1e684c17bf588ddc33a5b075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4829db0cbb7c4211a137656af0699bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824036f44c8a4a048506b8c56aeaefe6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b3c7f6fdb645c888ffb03ff38a3075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6756319956e4e01a45178abc677e00a",
            "placeholder": "​",
            "style": "IPY_MODEL_d13352ff8b6d4595aef733d118da6b96",
            "value": " 170498071/170498071 [00:02&lt;00:00, 89986789.06it/s]"
          }
        },
        "a87e5e05899948ef9aaac20e29275834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b008b3629b4246a2bbc006d2706e001f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824036f44c8a4a048506b8c56aeaefe6",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ec87fe1e684c17bf588ddc33a5b075",
            "value": 170498071
          }
        },
        "c3bdb06270f9459fbfee8112eaf9d28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21520b133b864ddfa14e6ed40984c53c",
            "placeholder": "​",
            "style": "IPY_MODEL_a87e5e05899948ef9aaac20e29275834",
            "value": "100%"
          }
        },
        "d13352ff8b6d4595aef733d118da6b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6756319956e4e01a45178abc677e00a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3471d569d0e4cbfbc222f3d99702315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3bdb06270f9459fbfee8112eaf9d28f",
              "IPY_MODEL_b008b3629b4246a2bbc006d2706e001f",
              "IPY_MODEL_a3b3c7f6fdb645c888ffb03ff38a3075"
            ],
            "layout": "IPY_MODEL_4829db0cbb7c4211a137656af0699bfb"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
